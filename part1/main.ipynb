{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql import SparkSession\n", "import re\n", "import json"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark = SparkSession.builder.appName('ChiSquared').getOrCreate()\n", "sc = spark.sparkContext"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset_path = '../reviews_devset_full.json'\n", "stopwords_path = '../stopwords.txt'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["regex = re.compile(r'[ \\t\\d()[\\]{}.!?,;:+=\\-_\"\\'`~#@&*%\u00e2\u201a\u00ac$\u00c2\u00a7\\\\/]+')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stopWords = set(sc.textFile(stopwords_path).collect())\n", "rdd_data = sc.textFile(dataset_path).map(lambda x: json.loads(x))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["generate an RDD with the category, articleID and keywords that are filtered by stopwords"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tokenized = rdd_data.flatMap(\n", "    lambda x: [(x['category'], x['asin'], word.lower()) for word in set(regex.split(x['reviewText'])) if word not in stopWords and len(word) > 1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["counts tokens occurrences throughout all documents, the result is a dictionary that looks like this: \"{'you': 4462, 'gift': 1642, 'cuisine': 19, 'page': 1441...}\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["token_total_counts = dict(tokenized.map(lambda x: (x[2], x[1])) \\\n", "        .groupByKey() \\\n", "        .map(lambda x: (x[0], (len(set(x[1]))))).collect())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Count the tokens for each category"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["category_tokens_counts = tokenized.map(lambda x: ((x[0], x[2]), x[1])) \\\n", "    .groupByKey() \\\n", "    .map(lambda x: (x[0][0], (x[0][1], len(set(x[1]))))) \\\n", "    .groupByKey()\n", "# we end up with an RDD that contains elements like this\n", "#[\n", "#('category_name', ('token_name', 'total_token_ocurrences_in_category'))\n", "#('category_name', ('token_name2', 'total_token_ocurrences_in_category'))\n", "#('category_name2', ('token_name', 'total_token_ocurrences_in_category'))\n", "#...]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Count the documents for each category"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["categories_document_counts = dict(rdd_data.map(lambda x: (x['category'], x['asin'])) \\\n", "                                  .groupByKey() \\\n", "                                  .map(lambda x: (x[0], len(x[1]))) \\\n", "                                  .collect())\n", "# we end up with a dictionary that looks like this\n", "#{'Patio_Lawn_and_Garde': 994,\n", "# 'Apps_for_Android': 2638,\n", "# 'Book': 22507,\n", "# 'Sports_and_Outdoor': 3269\n", "# ...}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Total number of documents"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N = rdd_data.count()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calculate_chi_squared(category):\n", "    # c is referred to the category, t is referred to the token(word)\n", "    # In order to be able to calculate chi-square, we need to have the following values for each token:\n", "    # N- total number of retrieved documents\n", "    # A- number of documents in c which contain t\n", "    # B- number of documents not in c which contain t\n", "    # C- number of documents in c without t - this can be derived from getting the total number of documents for the category and subtracting A from it\n", "    # D- number of documents not in c without t\n", "    # the formula for calculating chi-squared is\n", "    # N(AD - BC)^2 / (A+B)(A+C)(B+D)(C+D)\n", "    category_name = category[0]\n", "    token_chi = {}\n", "    for token, token_count_in_category in category[1]:\n", "        A = token_count_in_category\n", "        B = token_total_counts[token] - A\n", "        C = categories_document_counts[category_name] - A\n", "        D = N - categories_document_counts[category_name] - B\n", "        R: float = (N * (((A * D) - (B * C)) ** 2)) / ((A + B) * (A + C) * (B + D) * (C + D))\n", "        token_chi[token] = R\n", "    top_tokens = sorted(token_chi.items(), key=lambda x: x[1], reverse=True)[:75]\n", "    top_tokens_str = f'<{category_name}> {\" \".join([f\"{token}:{chi_value}\" for token, chi_value in top_tokens])}\\n'\n", "    return top_tokens_str"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculate chi-squared values for each category and word"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["chi_squared_strings = category_tokens_counts.map(calculate_chi_squared)\n", "with open(\"output.txt\", 'w') as f:\n", "    for category_row in sorted(chi_squared_strings.collect()):\n", "        f.write(category_row)\n", "        print(category_row)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}